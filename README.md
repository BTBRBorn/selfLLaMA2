# About
This repository is a from scratch implementation of LLaMA2-3 models.
It is still under development but when it is done, it will include inference and training
code together.
For now, model_inference.py is implemented which can be used to create a model for inference.
You can see the implementations of RoPE(Rotary Positional Encodings), KV cache,
GQA(Grouped Query Attention), SwiGLU activation which are essential components of modern LLMs.